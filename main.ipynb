{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Neural Network for MNIST Classification Using NumPy\n",
    "\n",
    "In this notebook, we will use a neural network to predict the number in an image. We will use the MNIST dataset, which is a dataset of 28x28 images of handwritten digits. The dataset contains 60,000 training images and 10,000 test images. Each image is labeled with the corresponding digit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries\n",
    "\n",
    "We will use the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import struct # get image data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "\n",
    "First, we will load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "5\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000011011100000\n",
      "0000000000011111111111100000\n",
      "0000000011111111110000000000\n",
      "0000000011111111110000000000\n",
      "0000000001011100010000000000\n",
      "0000000000011000000000000000\n",
      "0000000000011100000000000000\n",
      "0000000000001100000000000000\n",
      "0000000000000111000000000000\n",
      "0000000000000011100000000000\n",
      "0000000000000001111000000000\n",
      "0000000000000000011100000000\n",
      "0000000000000000011100000000\n",
      "0000000000000001111100000000\n",
      "0000000000000111111100000000\n",
      "0000000000001111110000000000\n",
      "0000000000111111000000000000\n",
      "0000000111111100000000000000\n",
      "0000011111111000000000000000\n",
      "0000111111100000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000111000000000\n",
      "0000000000000001111100000000\n",
      "0000000000000011111100000000\n",
      "0000000000000111110110000000\n",
      "0000000000011111110111000000\n",
      "0000000000011110110011000000\n",
      "0000000000111100000011000000\n",
      "0000000001111000000011100000\n",
      "0000000011100000000011100000\n",
      "0000000011000000000011100000\n",
      "0000000111000000000011100000\n",
      "0000000110000000000011100000\n",
      "0000000110000000000111000000\n",
      "0000000110000000001110000000\n",
      "0000000110000000011100000000\n",
      "0000000110000000111000000000\n",
      "0000000111000111110000000000\n",
      "0000000111111111100000000000\n",
      "0000000111111110000000000000\n",
      "0000000011111000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "4\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000001000000\n",
      "0000000000000000000001000000\n",
      "0000010000000000000011000000\n",
      "0000110000000000000011000000\n",
      "0000110000000000000110000000\n",
      "0000110000000000000110000000\n",
      "0000110000000000000110000000\n",
      "0001100000000000001110000000\n",
      "0001100000000000011100000000\n",
      "0001100000001111111100000000\n",
      "0001111111111110001100000000\n",
      "0000011111000000001100000000\n",
      "0000000000000000011100000000\n",
      "0000000000000000011000000000\n",
      "0000000000000000011000000000\n",
      "0000000000000000011000000000\n",
      "0000000000000000011000000000\n",
      "0000000000000000011100000000\n",
      "0000000000000000011100000000\n",
      "0000000000000000001100000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n",
      "0000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "image_file:str = \"./train-images.idx3-ubyte\"\n",
    "label_file:str = \"./train-labels.idx1-ubyte\"\n",
    "\n",
    "def read_idx(file:str) -> object:\n",
    "\twith open(file, 'rb') as f:\n",
    "\t\tzero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "\t\tshape:tuple = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "\t\treturn np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)\n",
    "\n",
    "image_data:object = read_idx(image_file)\n",
    "print(image_data.shape)\n",
    "label_data:object = read_idx(label_file)\n",
    "for i in range(3):\n",
    "\tprint(label_data[i])\n",
    "\tfor j in range(0, image_data.shape[1]):\n",
    "\t\tfor k in range(0, image_data.shape[2]):\n",
    "\t\t\tif image_data[i][j][k] > 127:\n",
    "\t\t\t\tprint(\"1\", end=\"\")\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"0\", end=\"\")\n",
    "\t\tprint(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the neural network\n",
    "\n",
    "Next, we will create a neural network & train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 2.304340548869987\n",
      "Epoch 5, Loss: 2.298829195990266\n",
      "Epoch 10, Loss: 2.2927531845543534\n",
      "Epoch 15, Loss: 2.284759239654879\n",
      "Epoch 20, Loss: 2.2734159610461333\n",
      "Epoch 25, Loss: 2.256937469695447\n",
      "Epoch 30, Loss: 2.233081524923437\n",
      "Epoch 35, Loss: 2.1992654331961345\n",
      "Epoch 40, Loss: 2.152844245623377\n",
      "Epoch 45, Loss: 2.0912937903266933\n",
      "Epoch 50, Loss: 2.0123410036099583\n",
      "Epoch 55, Loss: 1.9145460333887507\n",
      "Epoch 60, Loss: 1.7989010375346504\n",
      "Epoch 65, Loss: 1.6704877064573498\n",
      "Epoch 70, Loss: 1.5379612639931388\n",
      "Epoch 75, Loss: 1.4104419171989566\n",
      "Epoch 80, Loss: 1.294251276131505\n",
      "Epoch 85, Loss: 1.191974249550084\n",
      "Epoch 90, Loss: 1.103491323720678\n",
      "Epoch 95, Loss: 1.0273988338452178\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork:\n",
    "\tdef __init__(self, input_size:int, hidden_size:int, output_size:int) -> None:\n",
    "\t\tself.W1:object = np.random.randn(input_size, hidden_size) * 0.01\n",
    "\t\tself.b1:object = np.zeros((1, hidden_size))\n",
    "\t\tself.W2:object = np.random.randn(hidden_size, output_size) * 0.01\n",
    "\t\tself.b2:object = np.zeros((1, output_size))\n",
    "\n",
    "\tdef relu(self, Z:object) -> object:\n",
    "\t\treturn np.maximum(0, Z)\n",
    "\n",
    "\tdef relu_derivative(self, Z:object) -> object:\n",
    "\t\treturn Z > 0\n",
    "\n",
    "\tdef softmax(self, Z:object) -> object:\n",
    "\t\texpZ:object = np.exp(Z - np.max(Z, axis=1, keepdims=True))\n",
    "\t\treturn expZ / np.sum(expZ, axis=1, keepdims=True)\n",
    "\n",
    "\tdef cross_entropy_loss(self, Y:object, Y_hat:object) -> object:\n",
    "\t\tm = Y.shape[0]\n",
    "\t\tlog_likelihood = -np.log(Y_hat[range(m), np.argmax(Y, axis=1)])\n",
    "\t\tloss = np.sum(log_likelihood) / m\n",
    "\t\treturn loss\n",
    "\n",
    "\tdef forward(self, X:object) -> object:\n",
    "\t\tself.Z1:object = np.dot(X, self.W1) + self.b1\n",
    "\t\tself.A1:object = self.relu(self.Z1)\n",
    "\t\tself.Z2:object = np.dot(self.A1, self.W2) + self.b2\n",
    "\t\tself.A2:object = self.softmax(self.Z2)\n",
    "\t\treturn self.A2\n",
    "\n",
    "\tdef backward(self, X:object, Y:object, learning_rate:float) -> None:\n",
    "\t\tm:object = X.shape[0]\n",
    "\n",
    "\t\tdZ2:object = self.A2 - Y\n",
    "\t\tdW2:object = np.dot(self.A1.T, dZ2) / m\n",
    "\t\tdb2:object = np.sum(dZ2, axis=0, keepdims=True) / m\n",
    "\n",
    "\t\tdA1:object = np.dot(dZ2, self.W2.T)\n",
    "\t\tdZ1:object = dA1 * self.relu_derivative(self.Z1)\n",
    "\t\tdW1:object = np.dot(X.T, dZ1) / m\n",
    "\t\tdb1:object = np.sum(dZ1, axis=0, keepdims=True) / m\n",
    "\n",
    "\t\tself.W1 -= learning_rate * dW1\n",
    "\t\tself.b1 -= learning_rate * db1\n",
    "\t\tself.W2 -= learning_rate * dW2\n",
    "\t\tself.b2 -= learning_rate * db2\n",
    "\n",
    "\tdef train(self, X:object, Y:object, epochs:int, learning_rate:float) -> None:\n",
    "\t\tfor epoch in range(epochs):\n",
    "\t\t\tY_hat:object = self.forward(X)\n",
    "\t\t\tloss:object = self.cross_entropy_loss(Y, Y_hat)\n",
    "\t\t\tself.backward(X, Y, learning_rate)\n",
    "\t\t\tif epoch % 5 == 0:\n",
    "\t\t\t\tprint(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "input_size = image_data.shape[1] * image_data.shape[2]\n",
    "hidden_size = 128\t# Number of hidden neurons\n",
    "output_size = 10\t# 10 classes (digits 0-9)\n",
    "epochs = 100\t\t# Number of training iterations\n",
    "learning_rate = 0.1\t# Learning rate\n",
    "\n",
    "x_train = image_data.reshape(image_data.shape[0], -1) / 255\n",
    "y_train = np.eye(10)[label_data]\n",
    "\n",
    "nn = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "nn.train(x_train, y_train, epochs, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Finally, we will test the neural network on the test dataset to see how accurate it is for unseen input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 79.61%\n"
     ]
    }
   ],
   "source": [
    "x_test = read_idx(\"./t10k-images.idx3-ubyte\").reshape(10000, -1) / 255\n",
    "y_test = np.eye(10)[read_idx(\"./t10k-labels.idx1-ubyte\")]\n",
    "y_test_pred = nn.forward(x_test)\n",
    "\n",
    "accuracy = np.mean(np.argmax(y_test_pred, axis=1) == np.argmax(y_test, axis=1))\n",
    "print(f\"Test set accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
